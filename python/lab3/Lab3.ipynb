{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB3: Sparsity\n",
    "Author: Mathurin Massias (mathurin.massias@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lab3_utils import create_random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generation and model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(n_samples, n_features, n_informative_features, \n",
    "                    noise_level):\n",
    "    X, y = create_random_data(n_samples, n_features, n_informative_features, \n",
    "                          noise_level=noise_level)\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    train_size = 0.8  # proportion of dataset used for training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, shuffle=False, train_size=train_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "n_features = 200\n",
    "n_informative_features = 50\n",
    "\n",
    "# first, noiseless data, split in train and test/validation parts\n",
    "X_train, X_test, y_train, y_test = train_test_data(\n",
    "    n_samples, n_features, n_informative_features, noise_level=0.)\n",
    "print(\"Training dataset shape:\", X_train.shape)\n",
    "print(\"Testing dataset shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, the objective function of the ElasticNet optimization is:\n",
    "$$\\frac{1}{2 \\times \\text{n_samples}} \\Vert y - X \\beta \\Vert_2^2 + \\alpha \\times \\left( \\text{l1_ratio} \\times \\Vert \\beta \\Vert_1 + \\frac{1 - \\text{l1_ratio}}{2} \\Vert \\beta \\Vert_2^2\\right)$$\n",
    "\n",
    "See the docstring for more information in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticNet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a classifier with arbitrary values for L1 and L2 penalization\n",
    "clf = ElasticNet(alpha=0.1, l1_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model and print some its first coefficients\n",
    "# beware that sklearn fits an intercept by default\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"50 first coefficients of estimated w:\\n\", clf.coef_[:50])\n",
    "print(\"Intercept: %f\" % clf.intercept_)\n",
    "print(\"Nonzero coefficients: %d\" % (clf.coef_ != 0.).sum())\n",
    "print(\"Training error: %.4f\" % np.mean((y_train - clf.predict(X_train)) ** 2))\n",
    "# TODO compute testing error on left out data\n",
    "# print(\"Testing error: %.4f\" % )\n",
    "# TODO bonus: why is clf.predict(X_train) not equal to X_train @ clf.coef_? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the influence of l1_ratio on the sparsity of the solution\n",
    "# and on the train /test error\n",
    "l1_ratios = [0., 0., 0., 0., 0.]  # TODO choose your own values between 0 and 1\n",
    "\n",
    "train_errs = np.zeros(len(l1_ratios))\n",
    "test_errs = np.zeros_like(train_errs)\n",
    "sparsity = np.zeros_like(train_errs)\n",
    "\n",
    "for i, l1_ratio in enumerate(l1_ratios):\n",
    "    clf = # TODO; you may need to tune alpha a bit too.\n",
    "    # TODO fit the model on train data\n",
    "    # TODO compute train and test errors\n",
    "    train_errs[i] = \n",
    "    test_errs[i] = \n",
    "    sparsity[i] = # number of non-zero elements in clf.coef_\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(l1_ratios, test_errs, label='Test error')\n",
    "plt.plot(l1_ratios, train_errs, label='Train error')\n",
    "plt.xlabel(\"l1_ratio\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(l1_ratios, sparsity)\n",
    "plt.ylabel(r'$||w||_0$'')\n",
    "plt.xlabel('l1_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do the same for the influence of alpha, with a fixed l1_ratio\n",
    "# What happens when alpha becomes too big?\n",
    "alphas = np.geomspace(1e-4, 1e4, num=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check again the influence of regularization when there is noise in the data.\n",
    "X_train, X_test, y_train, y_test = train_test_data(\n",
    "    n_samples, n_features, n_informative_features, noise_level=0.5)\n",
    "# TODO: plot train/test curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Influence of dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•I.E(Prediction and selection) \n",
    "Considering the elastic net regularization, we \n",
    "want to study the sensitivity of training and test errors with respect to thechoice of regularization parameters and with respect to the number of relevantfeatures of the solution, by changing one parameter at a time.  To that end,you should try to pick some parameters, or run them in a loop, by exploitingthe code inl1l2demosimple.m.  Namely, study what happens as– \n",
    "\n",
    "I.E1...  you change the regularization parameterL1parassociated withthe`1-norm.– I.E2...  you change (increase or decrease) the regularization parameterL2parassociated with the`2-norm.Hint:Try the following fixed parameters:  20 points of dimension 100,with 15 relevant features, a noise level equal to 1 andL1par=0.1.– IE.3...   the  size  of  the  training  set  grows  (this  is  not  the  same  asgenerating different training sets of increasing size!).Hint:Try the same parameters as above, withL2par=0.– I.E4...  the amount of noise on the generated data grows (the test setis generated with the same parameters as the training set).•I.F(Largep, smalln)Perform experiments similar to those above but nowchangingp(dimensionality of the points),n(number of training points) ands(number of relevant variables).  In particular,  look at how do the resultsbehave whenp\u001d",
    "n, depending whethers < nholds or not (e.g.  tryn= 80andp= 300).  \n",
    "            Try to identify different regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, vary $n, p$ and $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = # TODO\n",
    "n_features = # TODO\n",
    "n_informative_features = # TODO\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_data(\n",
    "    n_samples, n_features, n_informative_features, noise_level=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter selection with cross validation\n",
    "In the next section, we use scikit-learn's built in functions to perform cross validated selection of alpha and l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_data(\n",
    "    n_samples, n_features, n_informative_features, noise_level=0.5)\n",
    "clf = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal values for l1_ratio and alpha: %s, %.2e\" % (clf.l1_ratio_, clf.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some data verifying $y = \\text{sign}(X \\beta^\\star)$ where $\\beta^\\star$ is unknown and $s$-sparse -- but you do not know $s$. the goal of this part is to infer it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"../../data/part3-data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"X\"]\n",
    "y = data[\"Y\"][:, 0]\n",
    "print(X.shape, y.shape)\n",
    "# TODO check numerically that y only contains values equal to 1 or -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you must infer $s$.\n",
    "A first possible approach is to use the Cross-Validation procedure used in the previous part: find the sparsity of the optimal $\\beta$ obtained by cross-validation on a grid of values for $\\alpha$ and l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO find optimal s from a CV point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to try to estimate $s$ is to measure the correlation between\n",
    "the columns of $X$ and $y$. Indeed, the zero coefficients in $\\beta^\\star$ will ignore the\n",
    "corresponding columns in $X$ while generating $y$. Can you also identify the indices of these features ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute correlation\n",
    "# corr = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort:\n",
    "idx = np.argsort(corr)\n",
    "plt.plot(corr[idx[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO identify the cutoff numerically, get s \n",
    "# and the indices of highest correlated features\n",
    "# highly_corr_feats ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use again the code of the first part, and tune the sparsity parameter l1_ratio so that\n",
    "it selects only $s$ features ($s$ being your sparsity estimate from the previous\n",
    "question). Look at which are the selected features in your solution. Do they\n",
    "correspond to the ones you identified with the correlation approach? \n",
    "If they do not, can you figure out why does this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
